{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON to Data conversion\n",
    "## Author: [Jeremiah Croshaw](https://linktr.ee/jeremiahcroshaw)\n",
    "#### Last Edited: Sept 23 2020\n",
    "\n",
    "Since this code was written while employed by [Quantum Silicon Inc.](https://www.quantumsilicon.com/), I have been advised to share it under the GNU-GPL\n",
    "***\n",
    "Copyright (C) 2020  Jeremiah Croshaw\n",
    "\n",
    "This program is free software; you can redistribute it and/or\n",
    "modify it under the terms of the GNU General Public License\n",
    "as published by the Free Software Foundation; version 2\n",
    "of the License.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program; if not, write to the Free Software\n",
    "Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n",
    "***\n",
    "\n",
    "### This code was used to convert the labelled data .JSON file (made with [labelme](http://labelme.csail.mit.edu/Release3.0/)) into useable training data for CNN training.\n",
    "\n",
    "### This code was developed for follow up work to our [published work](https://iopscience.iop.org/article/10.1088/2632-2153/ab6d5e) on defect segmentation of scanning probe images of the H-Si(100) surface.  \n",
    "The included .SXM file is a subsection of the total data set. Details regarding the upgraded data set and neural network are found in Croshaw's PhD Thesis\n",
    "\n",
    "author corresponence: croshaw@ualberta.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion,distance_transform_edt\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the defects have been extracted and converted into a binary map of an image, the euclidian distance transform is taken to approximate the centre of each labelled defect.  This series of functions uses finds each maximum in the distance transform with the assumption that each peak corresponds to the centre of the defect.  Once the centre of the defect is known, it can be cropped for future use.\n",
    "Variations of these functions are used in multiple examples, [here](https://stackoverflow.com/questions/16842823/peak-detection-in-a-noisy-2d-array) is where I got it.\n",
    "#### detect_peaks(image):\n",
    "\n",
    "***\n",
    "input: \n",
    "- image -this corresponds to the euclidean distance transform of a binary mask of the defects.\n",
    "\n",
    "output: \n",
    "- detected_peaks -a mask containing only peaks\n",
    "\n",
    "#### filter_quadratic(data,condition):\n",
    "applies a filter to remove any peaks that are too close to each other (if they are within a certain distance, they are likely from the same defect)\n",
    "***\n",
    "input:\n",
    "- data -The mask of images with the peaks marked\n",
    "- condition -a reference to the following function the_condition(xs,ys) which defines an acceptable distance between peaks\n",
    "\n",
    "output:\n",
    "- result -The filtered peaks\n",
    "\n",
    "#### the_condition(xs,ys):\n",
    "used to mark an acceptable distance between two points.  If xs is too close to previous peaks (stored in ys) then a FALSE is returned and the point xs is not added to ys.\n",
    "***\n",
    "input:\n",
    "- xs,ys - arrays of coordinates to compare \n",
    "\n",
    "output:\n",
    "- returns a function which indicates TRUE if the condition is met, FALSE if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(image):\n",
    "    \"\"\"\n",
    "    Takes an image and detect the peaks usingthe local maximum filter.\n",
    "    Returns a boolean mask of the peaks (i.e. 1 when\n",
    "    the pixel's value is the neighborhood maximum, 0 otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    # define an 8-connected neighborhood\n",
    "    neighborhood = generate_binary_structure(2,2)\n",
    "\n",
    "    #apply the local maximum filter; all pixel of maximal value \n",
    "    #in their neighborhood are set to 1\n",
    "    local_max = maximum_filter(image, footprint=neighborhood)==image\n",
    "    #local_max is a mask that contains the peaks we are \n",
    "    #looking for, but also the background.\n",
    "    #In order to isolate the peaks we must remove the background from the mask.\n",
    "\n",
    "    #we create the mask of the background\n",
    "    background = (image==0)\n",
    "\n",
    "    #a little technicality: we must erode the background in order to \n",
    "    #successfully subtract it form local_max, otherwise a line will \n",
    "    #appear along the background border (artifact of the local maximum filter)\n",
    "    eroded_background = binary_erosion(background, structure=neighborhood, border_value=1)\n",
    "\n",
    "    #we obtain the final mask, containing only peaks, \n",
    "    #by removing the background from the local_max mask (xor operation)\n",
    "    detected_peaks = local_max ^ eroded_background\n",
    "\n",
    "    return detected_peaks\n",
    "\n",
    "def filter_quadratic(data,condition):\n",
    "    result = []\n",
    "    for element in data:\n",
    "        if all(condition(element,other) for other in result):\n",
    "            result.append(element)\n",
    "    return result\n",
    "\n",
    "def the_condition(xs,ys):\n",
    "    return sum((x-y)*(x-y) for x,y in zip(xs,ys)) > 3 #change this condition if you want the acceptable peaks to be closer together or further apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize(image):\n",
    "just a simply normalize filter for images\n",
    "***\n",
    "\n",
    "input\n",
    "- image - the image to normalize\n",
    "\n",
    "output\n",
    "- image - thie image after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = (image-np.min(image))*255/(np.max(image)-np.min(image))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the JSON files and create binary mask for each defect\n",
    "***\n",
    "imports the json_files and corresponding images and extracts the defects and contour coordinates from the .json file.  It then creates a mask of each defect label creating a set of binary arrays corresponding to each defect in the .json files.  the resulting list all_defects will have a size of (number of images,number of labels + 1,pixels_x,pixels_y).  the + 1 is the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\images\\tile_scan_084_bwd.jpg\n",
      ".\\images\\tile_scan_082_fwd.jpg\n",
      "(2, 14, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "#define locations where json files and images are saved.\n",
    "json_folder = \".\\\\json_files\" \n",
    "image_folder = \".\\\\images\"\n",
    "\n",
    "all_defects = [] # empty list used to store the binary masks for the defects.  Will end up containing the image, and a binary mask for each of the 13 defects \n",
    "defect_classes = np.array(['DB','As2','dihydride','single_dihydride','1by1','3by1','dot','raised_silicon','etch_pit','gunk','step_edge','missing_dimer','unknown'])\n",
    "\n",
    "defects_count = np.full((defect_classes.shape),0)\n",
    "defects_pixels = np.full((defect_classes.shape),0)\n",
    "\n",
    "files = os.listdir(json_folder)\n",
    "\n",
    "for i in range(len(files)): #going over all json folders\n",
    "\n",
    "    print(image_folder + '\\\\' + files[i][:-4] + 'jpg')\n",
    "    img = cv2.imread(image_folder + '\\\\' + files[i][:-4] + 'jpg',0) # loads the image\n",
    "    defects = np.full((14,img.shape[0],img.shape[1]),0) #create an empty array for defect masks from json\n",
    "    defects[0] = img #set first entry as image\n",
    "    with open(json_folder + '\\\\' + files[i]) as f: #open the json file\n",
    "        datastore = json.load(f)\n",
    "    f.close()\n",
    "    for x in range(len(datastore['shapes'])):\n",
    "        label = datastore['shapes'][x]['label']#extract label from json file\n",
    "\n",
    "        if label == 'raised_silcon': #spelling mistake I didn't want to fix\n",
    "            index = 7\n",
    "        else:\n",
    "            index = int(np.argwhere(defect_classes == label))\n",
    "        #print(label,\": \", index)\n",
    "\n",
    "        defects_count[index] = defects_count[index] + 1 #count the defects labelled\n",
    "\n",
    "        if datastore['shapes'][x]['shape_type'] == 'polygon': #if it's a polygon shape, draw a polygon using cv2\n",
    "            points = np.asarray(datastore['shapes'][x]['points'],int)\n",
    "            cv2.fillPoly(defects[index+1],np.int32([points]),1)\n",
    "\n",
    "        if datastore['shapes'][x]['shape_type'] == 'rectangle': #if it's a rectangle, draw a rectangle using cv2\n",
    "            points = np.asarray(datastore['shapes'][x]['points'],int)\n",
    "            cv2.rectangle(defects[index+1],(points[0][0],points[0][1]),(points[1][0],points[1][1]),1,-1)\n",
    "    \n",
    "    for x in range(len(defect_classes)): #sum over pixels here\n",
    "        defects_pixels[x] = defects_pixels[x] + np.sum(defects[x+1])\n",
    "    all_defects.append(defects)\n",
    "\n",
    "all_defects = np.asarray(all_defects)\n",
    "print(all_defects.shape) # should be (number of immages, number of classes + 1, pixels_x, pixels_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .h5 file from the binary masks\n",
    "***\n",
    "takes the full binary masks and applies operations to them (i.e. reduce size, rotate, filp) to increase the number of images available for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n",
      "the complete dataset size:  (1792, 15, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#plt.imshow(all_defects[1][1])\n",
    "#plt.show()\n",
    "\n",
    "complete_dataset = [] #complete data set is used to store the flipped, rotated, and cropped images as well.\n",
    "rotation = 0\n",
    "for r in range(0,1): # this loop runs over the rotation angle for each image.  Set to 4 if you want 4 90 degree rotations\n",
    "    for i in range(0,all_defects.shape[0]):#loops over number of json files\n",
    "        interval = 8 # this is the factor in which the size fo the images are reduced.  8 means a 1024 x 1024 image will be reduced to 64 128 x 128 images\n",
    "        pixel_range = int(1024/interval)\n",
    "\n",
    "        for j in range(0,interval): #loops over number of times we divide the image\n",
    "            for k in range(0,interval):\n",
    "                all_defects[i][0][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range] = normalize(all_defects[i][0][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range])\n",
    "\n",
    "            #normal images\n",
    "                segment = []\n",
    "                for l in range(0,len(all_defects[i])): #loops over number of defects per json file\n",
    "                    if l == 1: # need to create an H-Si label.  This array is 1 if all other defects are 0, the l = 0 condition puts it right after the image before the DB class\n",
    "                        H_Si = np.full((pixel_range,pixel_range),1.)\n",
    "                        for x in range(0,len(all_defects[i])):\n",
    "                            H_Si[all_defects[i][x][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range] == 1] = 0\n",
    "                        H_Si = H_Si.tolist()\n",
    "                        segment.append(np.rot90(H_Si,k=rotation))\n",
    "                        segment.append(np.rot90(all_defects[i][l][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range],k=rotation))\n",
    "                        complete_dataset.append(segment)\n",
    "                    else:\n",
    "                        segment.append(np.rot90(all_defects[i][l][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range],k=rotation))\n",
    "                        complete_dataset.append(segment)\n",
    "            \"\"\"\n",
    "            #################################\n",
    "            #you can uncomment this section if you want to include image transposes as well\n",
    "            #transpose images\n",
    "                segment = []\n",
    "                for l in range(0,len(all_defects[i])): #loops over number of defects per json file\n",
    "                    if l == 1: # need to create an H-Si label.  This array is 1 if all other defects are 0, the l = 0 condition puts it right after the image before the DB class\n",
    "                        H_Si = np.full((pixel_range,pixel_range),1.)\n",
    "                        for x in range(0,len(all_defects[i])):\n",
    "                            H_Si[all_defects[i][x][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range] == 1] = 0\n",
    "                        H_Si = H_Si.tolist()\n",
    "                        segment.append(np.rot90(np.flip(H_Si),k=rotation))\n",
    "                        segment.append(np.rot90(np.flip(all_defects[i][l][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range]),k=rotation))\n",
    "                        complete_dataset.append(segment)\n",
    "                    else:\n",
    "                        segment.append(np.rot90(np.flip(all_defects[i][l][j*pixel_range:(j+1)*pixel_range,k*pixel_range:(k+1)*pixel_range]),k=rotation))\n",
    "                        complete_dataset.append(segment)\n",
    "            #end of image transpose section\n",
    "            ################################\n",
    "            \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "# More filtering can be done to the data here such as add noise, or artifically normalize images to simulate this segment taken from a surface with a step edge in the image (or upper, middle, and lower if simulating a surface with two step edges)\n",
    "# These steps were only going to be done if the NN performance was poor, but were deemed unecessary after its performance was observed.\n",
    "\n",
    "complete_dataset = np.asarray(complete_dataset,dtype = int)# you may run into memory errors here if you include the rotation and transpose as well\n",
    "print(\"the complete dataset size: \",complete_dataset.shape)\n",
    "\n",
    "h5f = h5py.File('.\\\\defect_data.h5','w')\n",
    "h5f.create_dataset('complete_dataset',data = complete_dataset) # change the name here according to how the data has been filtered.\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting further information regarding the data set\n",
    "***\n",
    "This section shows how one can extract images of each defect from the larger scans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defect_count:  [ 83  17 211  24  42  14 277 167  76  26   1 102  96]\n",
      "defect_pixels: [48436 10336 46559  5392 13974  6756 33992 32071 23975 12668 24178 21166\n",
      " 33681]\n"
     ]
    }
   ],
   "source": [
    "#everything below here is for individual defects and stats\n",
    "\n",
    "defects_images = [[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "DB = []\n",
    "As2 = []\n",
    "dihydride = []\n",
    "single_dihydride = []\n",
    "onebyone = []\n",
    "threebyone = []\n",
    "dot = []\n",
    "raised_silicon = []\n",
    "etch_pit = []\n",
    "gunk = []\n",
    "step_edge = []\n",
    "missing_dimer = []\n",
    "unknown = []\n",
    "\n",
    "\n",
    "for i in range(0,all_defects.shape[0]):#number of json files\n",
    "    for j in range(1,all_defects.shape[1]):#different defects per json file, note we are skipping the image here\n",
    "        #take the distance transpose to create peaks at the centre of the defects\n",
    "        defect_ecl = distance_transform_edt(all_defects[i][j])*100\n",
    "        defect_ecl = gaussian_filter(defect_ecl,sigma = (5,5),order = 0) # apply a gaussian filter to smooth the transform\n",
    "        #find the peaks and output them as array\n",
    "        peaks = np.transpose(np.where(detect_peaks(defect_ecl))) # creates an array with coordinates to each peak corresponding to each defect\n",
    "\n",
    "\n",
    "        #filter peaks to remove ones that are from the same defect\n",
    "        true_peaks = np.asarray(filter_quadratic(peaks,the_condition))\n",
    "\n",
    "        for peak in range(0,true_peaks.shape[0]):\n",
    "            x_peak = true_peaks[peak][0]\n",
    "            y_peak = true_peaks[peak][1]\n",
    "            defect_size = 20 # adjust this if you want to vary the dimension (in pixels) of the defect cutout.\n",
    "            image_x = 1024\n",
    "            image_y = 1024\n",
    "            \n",
    "            # this is a filter to remove any peaks from defects that sit close to the edge of the larger images.\n",
    "            if defect_size < x_peak < image_x -defect_size and defect_size < y_peak < image_y -defect_size:\n",
    "                image = all_defects[i][0] #index\n",
    "                \n",
    "                ###################################################################\n",
    "                #Use this section if you want pure defects (defects which contain only one tip of defect)\n",
    "                #This section finds pure defects (no other defects in image cut)\n",
    "                other_defects = 0\n",
    "                for z in range(1,all_defects.shape[1]):\n",
    "                    other_defects = np.sum(all_defects[i][z][x_peak-defect_size:x_peak+defect_size,y_peak-defect_size:y_peak+defect_size])+other_defects\n",
    "                    #print(z,\": \",other_defects)\n",
    "                defect = np.sum(all_defects[i][j][x_peak-defect_size:x_peak+defect_size,y_peak-defect_size:y_peak+defect_size])\n",
    "                #print('defect',\": \", defect)\n",
    "                if other_defects-defect == 0:\n",
    "                    defect = image[x_peak-defect_size:x_peak+defect_size,y_peak-defect_size:y_peak+defect_size]\n",
    "                    defect = normalize(defect)\n",
    "                    defects_images[j-1].append(defect)\n",
    "                    #cv2.imwrite(\"defect_images_test\\\\\" + str(i) + \"_\" + str(j) + \"_pure.jpg\",defect)\n",
    "                else:\n",
    "                    pass\n",
    "                #end of single defect section\n",
    "                #####################################################################\n",
    "                \"\"\"\n",
    "                ####################################################################\n",
    "                #use this section if you don't care if the image contains more than one type of defect\n",
    "                defect = image[x_peak-defect_size:x_peak+defect_size,y_peak-defect_size:y_peak+defect_size]\n",
    "                defect = normalize(defect)\n",
    "                defects_images[j-1].append(defect)\n",
    "                cv2.imwrite(\"defect_images_test\\\\\" + str(i) + \"_\" + str(j) + \".jpg\",defect)\n",
    "                #end of multiple defect section\n",
    "                #####################################################################\n",
    "                \"\"\"\n",
    "            else: # skips the defect if it cuts into the edge of the image\n",
    "                pass\n",
    "\n",
    "# to create a set of h5 files for each defect type.\n",
    "#for x in range(0,len(defects_images)):\n",
    "    #h5f = h5py.File('single_defects_pure\\\\' + defect_classes[x] + '_pure.h5','w')\n",
    "    #h5f.create_dataset(defect_classes[x],data = defects_images[x])\n",
    "    #h5f.close()\n",
    "\n",
    "\n",
    "#plt.imshow(defects[0]*255)\n",
    "#plt.show()\n",
    "\n",
    "#The following are calculated directly from teh JSON files above\n",
    "print('defect_count: ', defects_count) #prints the number of defects for each class.\n",
    "print('defect_pixels:', defects_pixels) # prints the number of pixels that correspond to each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
